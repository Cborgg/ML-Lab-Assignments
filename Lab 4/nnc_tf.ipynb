{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7PTAzJ7Bwet"
   },
   "source": [
    "## Tensorflow\n",
    "\n",
    "Try to implement a feed forward Neural Network model for a classification problem\n",
    "\n",
    "Given a handwritten digit from MNIST classify it as 4 or 9 [4 & 9 are the most difficult digits to classify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgI3v6UsCjSM",
    "outputId": "0259009a-a3ed-4279-f5a5-42c58f1d563e"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Dataframe' from 'pandas' (/opt/conda/lib/python3.8/site-packages/pandas/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrn\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataframe,read_csv\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Dataframe' from 'pandas' (/opt/conda/lib/python3.8/site-packages/pandas/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy.random as rn\n",
    "from pandas import Dataframe,read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m d\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone\u001b[39m\u001b[38;5;124m'\u001b[39m:pd\u001b[38;5;241m.\u001b[39mSeries([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m]),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwo\u001b[39m\u001b[38;5;124m'\u001b[39m:pd\u001b[38;5;241m.\u001b[39mSeries([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m23\u001b[39m,\u001b[38;5;241m45\u001b[39m,\u001b[38;5;241m6\u001b[39m],index\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m))}\n\u001b[0;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataframe\u001b[49m(d)\n\u001b[1;32m      3\u001b[0m df\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "d={'one':pd.Series([1,2,3,4],index=['a','b','c','d']),'two':pd.Series([1,23,45,6],index=('a','b','c','d'))}\n",
    "df=pd.Dataframe(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
       "               '2013-01-05', '2013-01-06', '2013-01-07', '2013-01-08',\n",
       "               '2013-01-09', '2013-01-10'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date=pd.date_range('20130101',periods=10)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZE6KyoeG-Gd"
   },
   "source": [
    "### Data loading\n",
    "\n",
    "This data is saved in a python pickle format.  \n",
    "Here is the code to load the data and \n",
    "save it to different numpy arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "id": "BXdlSrzdHhSl",
    "outputId": "06183a1e-0fdb-44a2-9002-f76d98a9d5e4"
   },
   "outputs": [],
   "source": [
    "# Read the data \n",
    "train_df = pd.read_csv(\"/home/splab-ece/labs/fml/data/mnist/mnist_train.csv\")\n",
    "data = train_df.to_numpy()\n",
    "data = data.T;\n",
    "# Reading the data and labels\n",
    "tr_labels = data[0,:]\n",
    "tr_data   = data[1:,:]\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"/home/splab-ece/labs/fml/data/mnist/mnist_test.csv\")\n",
    "data = train_df.to_numpy()\n",
    "data = data.T\n",
    "# Reading the data and labels\n",
    "ts_labels = data[0,:]\n",
    "ts_data   = data[1:,:]\n",
    "\n",
    "print(tr_data.shape, ts_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us display Random 10 samples and their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     index \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint (\u001b[38;5;241m0\u001b[39m,\u001b[43mtr_data\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m     img \u001b[38;5;241m=\u001b[39m tr_data[:,index]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m5\u001b[39m,i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tr_data' is not defined"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "for i in range(10):\n",
    "    index = random.randint (0,tr_data.shape[0])\n",
    "    img = tr_data[:,index].reshape(28,28)\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.title('label = '+str(tr_labels[index]))\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation \n",
    "We want to train a Neural network classifier between classes 4 and 9\n",
    "\n",
    "we need to do the following  data preparation steps\n",
    "   - separate the training data of classes 4 and 9 \n",
    "   - make labels class 4 as zero and class 9 as 1 \n",
    "   - normalize input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Here we separate the training data and test data for \n",
    "    classes from all other data.    We also change the \n",
    "    labels of class 4 as zero and class 9 as 1\n",
    "'''\n",
    "# We separate training and labels for class 4 and 9 alone\n",
    "sub_index    = (tr_labels == 9) | (tr_labels == 4) # finding indexes\n",
    "tr_datasub  = tr_data[:,sub_index]  # separating training data\n",
    "tr_labelsub = tr_labels[sub_index] # separating training labels\n",
    "tr_labelsub[tr_labelsub==4] = 0\n",
    "tr_labelsub[tr_labelsub==9] = 1\n",
    "tr_labelsub = tr_labelsub.reshape(1,-1)\n",
    "\n",
    "# Repeat the process for test data\n",
    "sub_index    = (ts_labels == 9) | (ts_labels == 4) # finding indexes\n",
    "ts_datasub  = ts_data[:,sub_index]  # separating training data\n",
    "ts_labelsub = ts_labels[sub_index] # separating training labels\n",
    "ts_labelsub[ts_labelsub==4] = 0\n",
    "ts_labelsub[ts_labelsub==9] = 1\n",
    "ts_labelsub = ts_labelsub.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    "We have one more important step before training.\n",
    "i.e., feature normalization.   These inputs being images, \n",
    "they are always between 0 -255.   Here we divide all the \n",
    "features with 255, so that they are between 0 and1 \n",
    "'''\n",
    "tr_datasub = tr_datasub/255.0 \n",
    "ts_datasub = ts_datasub/255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 11791) (784, 1991)\n"
     ]
    }
   ],
   "source": [
    "print(tr_datasub.shape, ts_datasub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network in Tensorflow\n",
    "There are three steps in creating a neural network\n",
    "- Define the connections in the neural network\n",
    "- Model compile - set up loss functions \n",
    "- Learn the model - training via back propagation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-08 09:22:59.305935: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is the definition \n",
    "'''\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu',name='hid_1') )\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid',name='out'))\n",
    "#model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(0.0001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "history1 = model.fit(tr_datasub.T, tr_labelsub.T, batch_size=10, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on training data\n",
    "\n",
    "we use the trained parameter to evaluate the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the accuracy of test data.\n",
    "(loss, acc) = model.evaluate(ts_datasub.T,ts_labelsub.T)\n",
    "print(\"Classification accuracy \", acc*100 , '%')\n",
    "plt.plot(history1.history['loss'] );\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO \n",
    "\n",
    "Implment a logistic regression \n",
    "model using this framework and \n",
    "determine the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mcmodel = tf.keras.models.Sequential()\n",
    "mcmodel.add(tf.keras.Input(shape=(784,)))\n",
    "mcmodel.add(tf.keras.layers.Dense(50, activation='relu',name='hidden_1') )\n",
    "mcmodel.add(tf.keras.layers.Dense(10, activation='softmax',name='out'))\n",
    "mcmodel.summary()\n",
    "\n",
    "mcmodel.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "history = mcmodel.fit(tr_data.T, tr_labels, batch_size=10, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on training data\n",
    "\n",
    "we use the trained parameter to evaluate the accuracy on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the accuracy of test data.\n",
    "(loss, acc) = mcmodel.evaluate(ts_data.T,ts_labels)\n",
    "print(\"Classification accuracy \", acc*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO \n",
    "Create a Feedforward neural network with the following architectures for the 10 class classification problem\n",
    "\n",
    "- 3 layer neural network \n",
    "    - 2 hidden layers :-  100 neurons  and relu activation\n",
    "    - Output layer :- 10 neurons with softmax activation\n",
    "    \n",
    "- Same architecture as above  but with tanh instead of relu\n",
    "\n",
    "Compare the learning and prediction accuracies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data2 = tr_data.reshape((28,28,-1))\n",
    "ts_data2 = ts_data.reshape((28,28,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conv_model = tf.keras.models.Sequential()\n",
    "conv_model.add(tf.keras.Input(shape=(28,28,1)))\n",
    "conv_model.add(tf.keras.layers.Conv2D(16,(3,3)))\n",
    "conv_model.add(tf.keras.layers.MaxPooling2D())\n",
    "conv_model.add(tf.keras.layers.Conv2D(32,(3,3)))\n",
    "conv_model.add(tf.keras.layers.MaxPooling2D())\n",
    "conv_model.add(tf.keras.layers.Flatten())\n",
    "conv_model.add(tf.keras.layers.Dense(50, activation='relu',name='hidden_1') )\n",
    "conv_model.add(tf.keras.layers.Dense(10, activation='softmax',name='out'))\n",
    "conv_model.summary()\n",
    "\n",
    "conv_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(0.0001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "history = conv_model.fit(tr_data2.T, tr_labels, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the accuracy of test data.\n",
    "(loss, acc) = conv_model.evaluate(ts_data2.T,ts_labels.T)\n",
    "print(\"Classification accuracy \", acc*100 , '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO \n",
    "\n",
    "Add one more convolution and max pooling layer\n",
    "and re evaluate the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "SPML Course Environment",
   "language": "python",
   "name": "spml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
